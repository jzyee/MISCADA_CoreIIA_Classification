---
title: "R Notebook"
output: html_notebook
---

this notebook will be specifically for inception v3


```{r}
```


```{r}
train_y <- read.csv('train/class_list.csv')[2]

test_y <- read.csv('test/class_list.csv')[2]



#val_y <- read.csv('val/class_list.csv')[2]

```

```{r}
test_y[1:10,]
```

```{r}
library(magick)
library(png)
library(imager)
# <- array(rep(1, 1*218*230*3 ), dim=c(1,218,230,3))
sample_1 <- imager::load.image('train/img1000_y4.png')
image_bu <- array(rep(sample_1), dim=c(1,218,230,3))
str(image_bu)
# str(image_data(sample_1,'rgb'))#reads in as a greyscale image
# sample_1 <- image_scale(sample_1, '200')
# sample_1 <- image_data(sample_1,'rgb')
# str(sample_1)

```


```{r}
library("rsample")
set.seed(212)

library(reticulate)
use_python('C:/Users/Anaconda3')

load_img_data <- function(folder_name){
  
  files <- list.files(path=folder_name, pattern="*.png", full.names=TRUE, recursive=FALSE)
  print(length(files))
  output <- array(rep(0, length(files)*150*150*3 ), dim=c(length(files),150,150,3))
  print(str(output))
  for(idx in 1:length(files)){
    # x <- image_read(files[idx])
    # x <- image_scale(x, '200')
    # x <- image_data(x,'rgb')
    x <- imager::load.image(files[idx])
    x <- imager::resize(x, 150, 150)
    x <- array(rep(x), dim=c(1,150,150,3))
    x <- array_reshape(x, c(1,150,150,3))
    output[idx,,,] <- x
  }
  # output <- imagenet_preprocess_input(output)
  return(output)
}
#memory.limit(size=4000)
train_x <- load_img_data('train')
print(str(train_x))
#train_x <- imager::load.image('train/img1_y4.jpg')

```

```{r}
test_x <- load_img_data('test')
str(test_x)
```
```{r}
test_y
```


#need shuffling
```{r}
set.seed(101)
rows_idx <- sample(nrow(train_y))
train_y <- train_y[rows_idx,]
train_x <- train_x[rows_idx,,,]
rows_idx2 <-sample(nrow(test_y))
test_y <- test_y[rows_idx2,]
test_x <- test_x[rows_idx2,,,]
```



```{r}
# not needed for model making


#max(train_x)
#min(train_x)
plot(unlist(epil_train_final[1,]),type='l')
plot(as.raster(train_x[1,,,]))
print(train_y[1,])
hist(train_x[1,,,])
```

```{r}
test_y[1:10]
```


```{r}
library(reticulate)
use_python('C:/Users/Anaconda3/condabin') 
library(keras)
use_session_with_seed(44)

train_y.cat <- to_categorical(train_y)[,-1]
train_y.cat

#train_y
```

```{r}
test_y.cat <- to_categorical(test_y)[,-1]
test_y.cat
str(test_y)
```


```{r}
basic_v3 <- application_inception_v3(weights = 'imagenet',
                                         include_top = FALSE,
                                         input_shape = c(150,150,3))
```


```{r}




mod_v3 <-  keras_model_sequential() %>%
           basic_v3 %>%
           layer_flatten() %>%
           layer_dense(units = 256, activation='relu') %>%
           layer_dense(units = 5, activation='softmax')
```

```{r}
summary(mod_v3)
```
```{r}
freeze_weights(basic_v3)
summary(mod_v3)
```
```{r}
mod_v3 %>% compile(loss= 'categorical_crossentropy',
                   optimizer = 'adam',
                   metrics = 'accuracy')
```

```{r}
history <- mod_v3 %>% fit(train_x,
  train_y.cat,
  epochs = 10,
  batch_size = 50,
  validation_split = 0.2
)
```
```{r}
mod_v3 %>% evaluate(test_x, test_y.cat)
pred <- mod_v3 %>% predict_classes(test_x)
(tab <- table(Predicted = pred, Actual= unlist(test_y)))
100*diag(tab) / colSums(tab)
```
```{r}
str(test_y.cat)
str(pred)
```